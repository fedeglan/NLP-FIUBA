{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from collections import Counter\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Documentos como listas de términos:\n","[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","\n","Vocabulario del corpus:\n","['el', 'martes', 'muchas', 'es', 'gracias', 'de', 'hoy', 'que', 'dia']\n"]}],"source":["# Cada documento se transforma en una lista de términos\n","documentos_como_listas = [doc.split() for doc in corpus]\n","print(\"Documentos como listas de términos:\")\n","print(documentos_como_listas)\n","\n","# Armar un vector de términos no repetidos de todos los documentos\n","vocabulario = set()\n","for lista in documentos_como_listas:\n","    vocabulario.update(lista)\n","\n","# Convertir el conjunto a una lista\n","vocabulario = list(vocabulario)\n","print(\"\\nVocabulario del corpus:\")\n","print(vocabulario)"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>gracias</th>\n","      <th>hoy</th>\n","      <th>martes</th>\n","      <th>muchas</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Doc1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Doc2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Doc3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      de  dia  el  es  gracias  hoy  martes  muchas  que\n","Doc1   0    1   0   1        0    1       0       0    1\n","Doc2   1    1   1   1        0    1       1       0    0\n","Doc3   0    0   0   0        1    0       1       1    0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","def one_hot_encoding(docs):\n","    # Crear el vocabulario\n","    vocab = set(word for doc in docs for word in doc.split())\n","    vocab = sorted(list(vocab))\n","    \n","    # Crear una matriz de ceros\n","    one_hot = np.zeros((len(docs), len(vocab)), dtype=int)\n","    \n","    # Rellenar la matriz\n","    for i, doc in enumerate(docs):\n","        for word in doc.split():\n","            one_hot[i, vocab.index(word)] = 1\n","            \n","    return one_hot, vocab\n","\n","# Lista de textos\n","docs = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n","\n","# Obtener la representación One-Hot Encoding\n","matrix, vocabulary = one_hot_encoding(docs)\n","pd.DataFrame(np.array(matrix), \n","             columns = vocabulary, \n","             index = [\"Doc1\", \"Doc2\", \"Doc3\"])"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos?, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>gracias</th>\n","      <th>hoy</th>\n","      <th>martes</th>\n","      <th>muchas</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Doc1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Doc2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Doc3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      de  dia  el  es  gracias  hoy  martes  muchas  que\n","Doc1   0    1   0   1        0    1       0       0    1\n","Doc2   1    1   1   1        0    1       2       0    0\n","Doc3   0    0   0   0        1    0       1       1    0"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def term_frequency(docs):\n","    # Crear el vocabulario\n","    vocab = set(word for doc in docs for word in doc.split())\n","    vocab = sorted(list(vocab))\n","    \n","    # Crear una matriz de ceros\n","    tf_matrix = np.zeros((len(docs), len(vocab)), dtype=int)\n","    \n","    # Rellenar la matriz con frecuencias\n","    for i, doc in enumerate(docs):\n","        for word in doc.split():\n","            tf_matrix[i, vocab.index(word)] += 1\n","            \n","    return tf_matrix, vocab\n","\n","# Lista de textos\n","docs = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n","\n","# Obtener la representación de frecuencia de términos\n","matrix, vocabulary = term_frequency(docs)\n","pd.DataFrame(np.array(matrix), \n","             columns = vocabulary, \n","             index = [\"Doc1\", \"Doc2\", \"Doc3\"])"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>gracias</th>\n","      <th>hoy</th>\n","      <th>martes</th>\n","      <th>muchas</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Doc1</th>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","    </tr>\n","    <tr>\n","      <th>Doc2</th>\n","      <td>0.477121</td>\n","      <td>0.176091</td>\n","      <td>0.477121</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.352183</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Doc3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            de       dia        el   es   gracias       hoy    martes   \n","Doc1  0.000000  0.176091  0.000000  0.0  0.000000  0.176091  0.000000  \\\n","Doc2  0.477121  0.176091  0.477121  0.0  0.000000  0.176091  0.352183   \n","Doc3  0.000000  0.000000  0.000000  0.0  0.477121  0.000000  0.176091   \n","\n","        muchas       que  \n","Doc1  0.000000  0.477121  \n","Doc2  0.000000  0.000000  \n","Doc3  0.477121  0.000000  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["def compute_tfidf(docs):\n","    # Paso 1: Obtener el vocabulario\n","    vocab = set()\n","    for doc in docs:\n","        words = doc.split()\n","        vocab.update(words)\n","    vocab = sorted(list(vocab))\n","\n","    # Paso 2: Calcular la Frecuencia de Término (TF)\n","    tf = np.zeros((len(docs), len(vocab)))\n","    for i, doc in enumerate(docs):\n","        words = doc.split()\n","        word_count = Counter(words)\n","        for j, term in enumerate(vocab):\n","            tf[i, j] = word_count[term]\n","\n","    # Paso 3: Calcular la Frecuencia Inversa de Documento (IDF)\n","    idf = np.zeros(len(vocab))\n","    for i, term in enumerate(vocab):\n","        idf[i] = math.log10(len(docs) / sum([term in doc for doc in docs]))\n","\n","    # Paso 4: Calcular TF-IDF\n","    tfidf = tf * idf\n","\n","    return vocab, tfidf\n","\n","docs = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n","\n","vocab, tfidf_matrix = compute_tfidf(docs)\n","pd.DataFrame(np.array(tfidf_matrix), \n","             columns = vocab, \n","             index = [\"Doc1\", \"Doc2\", \"Doc3\"])\n"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["['que dia es hoy', 'hoy es un buen dia', 'martes el dia de hoy es martes', 'martes muchas gracias']\n"]}],"source":["import numpy as np\n","from collections import Counter\n","import math\n","\n","def compute_tfidf(docs):\n","    vocab = set()\n","    for doc in docs:\n","        words = doc.split()\n","        vocab.update(words)\n","    vocab = sorted(list(vocab))\n","    \n","    tf = np.zeros((len(docs), len(vocab)))\n","    for i, doc in enumerate(docs):\n","        words = doc.split()\n","        word_count = Counter(words)\n","        for j, term in enumerate(vocab):\n","            tf[i, j] = word_count[term]\n","\n","    idf = np.zeros(len(vocab))\n","    for i, term in enumerate(vocab):\n","        idf[i] = math.log10(len(docs) / sum([term in doc for doc in docs]))\n","\n","    tfidf = tf * idf\n","    return tfidf\n","\n","def rank_docs_by_similarity(docs, index):\n","    tfidf_matrix = compute_tfidf(docs)\n","    target = tfidf_matrix[index]\n","    \n","    similarities = []\n","    for i, doc_vector in enumerate(tfidf_matrix):\n","        sim = cosine_similarity(target, doc_vector)\n","        similarities.append((i, sim))\n","    \n","    sorted_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n","    \n","    return [docs[i[0]] for i in sorted_similarities]\n","\n","docs = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias', 'hoy es un buen dia']\n","\n","index = 0\n","print(rank_docs_by_similarity(docs, index))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
